{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "irish-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "absent-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data set\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-filter",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-casino",
   "metadata": {},
   "source": [
    "## flat_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "direct-disorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1 room', '2 room', '3 room', '4 room', '5 room', 'executive',\n",
       "       'multi generation'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train['flat_type'] == \"1-room\", 'flat_type'] = \"1 room\"\n",
    "train.loc[train['flat_type'] == \"2-room\", 'flat_type'] = \"2 room\"\n",
    "train.loc[train['flat_type'] == \"3-room\", 'flat_type'] = \"3 room\"\n",
    "train.loc[train['flat_type'] == \"4-room\", 'flat_type'] = \"4 room\"\n",
    "train.loc[train['flat_type'] == \"5-room\", 'flat_type'] = \"5 room\"\n",
    "\n",
    "# checking\n",
    "flat_type = np.unique(train.flat_type) \n",
    "flat_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-dance",
   "metadata": {},
   "source": [
    "## block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "vocational-metabolism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the block column to 1 if it has the number 4\n",
    "# converting the block column to 0 if it does not have the number 4\n",
    "train.loc[train['block'].str.contains('4'),'block'] = 1\n",
    "train.loc[train['block'].str.contains('4') == False, 'block'] = 0\n",
    "\n",
    "np.unique(train.block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-encounter",
   "metadata": {},
   "source": [
    "# storey_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "brown-secondary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01 to 06', '06 to 10', '10 to 15', '16 to 21', '21 to 25',\n",
       "       '25 to 30', '31 to 36', '36 to 40', '40 to 45', '46 to 51'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to 01 to 06, 06 to 10, 10 to 15, 16 to 21, 21 to 25, 25 to 30, \n",
    "# 31 to 36, 36 to 40, 40 to 45, 46 to 51\n",
    "# data is messy as it has lots of overlaps, so the partioning is to make\n",
    "# it more systematic\n",
    "# 01 to 06\n",
    "train.loc[train['storey_range'] == \"01 to 03\", 'storey_range'] = \"01 to 06\"\n",
    "train.loc[train['storey_range'] == \"01 to 05\", 'storey_range'] = \"01 to 06\"\n",
    "train.loc[train['storey_range'] == \"04 to 06\", 'storey_range'] = \"01 to 06\"\n",
    "# 06 to 10\n",
    "train.loc[train['storey_range'] == \"07 to 09\", 'storey_range'] = \"06 to 10\"\n",
    "# 10 to 15\n",
    "train.loc[train['storey_range'] == \"10 to 12\", 'storey_range'] = \"10 to 15\"\n",
    "train.loc[train['storey_range'] == \"11 to 15\", 'storey_range'] = \"10 to 15\"\n",
    "train.loc[train['storey_range'] == \"13 to 15\", 'storey_range'] = \"10 to 15\"\n",
    "# 16 to 21\n",
    "train.loc[train['storey_range'] == \"16 to 18\", 'storey_range'] = \"16 to 21\"\n",
    "train.loc[train['storey_range'] == \"16 to 20\", 'storey_range'] = \"16 to 21\"\n",
    "train.loc[train['storey_range'] == \"19 to 21\", 'storey_range'] = \"16 to 21\"\n",
    "# 21 to 25\n",
    "train.loc[train['storey_range'] == \"22 to 24\", 'storey_range'] = \"21 to 25\"\n",
    "# 25 to 30\n",
    "train.loc[train['storey_range'] == \"25 to 27\", 'storey_range'] = \"25 to 30\"\n",
    "train.loc[train['storey_range'] == \"26 to 30\", 'storey_range'] = \"25 to 30\"\n",
    "train.loc[train['storey_range'] == \"28 to 30\", 'storey_range'] = \"25 to 30\"\n",
    "# 31 to 36\n",
    "train.loc[train['storey_range'] == \"31 to 33\", 'storey_range'] = \"31 to 36\"\n",
    "train.loc[train['storey_range'] == \"31 to 35\", 'storey_range'] = \"31 to 36\"\n",
    "train.loc[train['storey_range'] == \"34 to 36\", 'storey_range'] = \"31 to 36\"\n",
    "# 36 to 40\n",
    "train.loc[train['storey_range'] == \"37 to 39\", 'storey_range'] = \"36 to 40\"\n",
    "# 40 to 45\n",
    "train.loc[train['storey_range'] == \"40 to 42\", 'storey_range'] = \"40 to 45\"\n",
    "train.loc[train['storey_range'] == \"43 to 45\", 'storey_range'] = \"40 to 45\"\n",
    "# 46 to 51\n",
    "train.loc[train['storey_range'] == \"46 to 48\", 'storey_range'] = \"46 to 51\"\n",
    "train.loc[train['storey_range'] == \"49 to 51\", 'storey_range'] = \"46 to 51\"\n",
    "\n",
    "# checking\n",
    "np.unique(train.storey_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-fluid",
   "metadata": {},
   "source": [
    "## Auxiliary- demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "flexible-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_demo = pd.read_csv('auxiliary-data/sg-population-demographics.csv')\n",
    "\n",
    "# population count across age in a particular subzone\n",
    "dicts = {}\n",
    "for area in np.unique(population_demo.subzone):\n",
    "    area_count = population_demo[population_demo['subzone'] == area]['count'].sum()\n",
    "    dicts[area] = area_count\n",
    "train['popcount_subzone'] = train['subzone'].map(dicts)\n",
    "\n",
    "# 490 was derived from central subzone in the population demographics\n",
    "# dataset. However, there is no such subzone in the main dataset. After\n",
    "# verifying it, central subzone is inferred to be 'city hall' in main \n",
    "# data set (beach road area)\n",
    "train.loc[train['subzone'] == \"city hall\", 'popcount_subzone'] = 490"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-hypothetical",
   "metadata": {},
   "source": [
    "## street_name, subzone, flat_model, region, planning_area, & town"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-request",
   "metadata": {},
   "source": [
    "street_name, subzone and region remain as it is (raw).\n",
    "\n",
    "Similiarly, I think no preprocessing is necessary for flat_model as these different models might have some impact on the resale price. For example maisonette is typically rare and so it might fetch a high price etc. \n",
    "\n",
    "The variable \"town\" is like a subset of the variable \"planning_area\". Two elements from the \"town\" set could be represented by either the planning area variable or other variables. More sepcifically, \"Kallang/Whampoa\" from the town set is essentially the same as \"Kallang\" from the planning area set. Also, \"central area\" from the town set could be captured by the variable \"region\". Thus, given these reasons, we have decided to drop \"town\" and just use planning_area.\n",
    "\n",
    "The location variables can be seen as a hierarchy. It could be arranged from the bigger to smaller set - 1) region, 2) planning_area, 3) subzone, and finally 4) street_name. \"region\" covers a large portion of non-overlapping areas of Singapore, while street_name is on a smaller scale that is specific to a particular place. This hierachy could aid in the prediction as bigger umbrella sets (region & planning_area) tend to be more global and coarse while smaller specific sets (subzone & street_name) tend to be more local and have finer distinctions between locations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-holder",
   "metadata": {},
   "source": [
    "# One-hot encoding on the categorical columns before analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "silent-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement one-hot encoding on categorical columns\n",
    "# do note that pd.get_dummies drop the original variable column by\n",
    "# default. Also note that \"block\" does not have to be one-hot encoded\n",
    "# because it is a binary variable already.\n",
    "# Also 'month' as Fiona mentioned, will be broken down to month and year\n",
    "# so the month portion of 'month' should be categorical also. I have not\n",
    "# included in, so please do so. \n",
    "categorical_cols = ['flat_type', 'street_name', 'storey_range', \n",
    "                    'flat_model', 'subzone','planning_area', 'region']\n",
    "train_dummies = pd.get_dummies(train, columns = categorical_cols)\n",
    "\n",
    "# selecting the data (note that 'month' is dropped as Fiona is doing)\n",
    "train_y = train['resale_price']\n",
    "train_final = train_dummies.drop(columns = ['town', 'eco_category', 'month',\n",
    "                                            'elevation', 'resale_price','lease_commence_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "communist-bullet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1337 columns after prerpocessing.\n",
      "The total number of observations is 431732\n"
     ]
    }
   ],
   "source": [
    "print('There are', len(train_final.columns), 'columns after prerpocessing.')\n",
    "print('The total number of observations is', train_final.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "viral-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the column names to csv\n",
    "columns_gerard = train_final.columns\n",
    "columns_gerard = pd.DataFrame(columns_gerard)\n",
    "columns_gerard.to_csv('columns_gerard.csv',index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-captain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
